{
	"nodes":[
		{"id":"d866dfdbea90a30d","x":80,"y":-480,"width":500,"height":510,"type":"text","text":"是：完全依赖 AI\n认知能力退化风险： - 长期依赖 AI 决策，自主判断力下降，如投资、学习规划等。 - 创造力因 AI 生成内容便捷性受抑制。 应对策略： - 每周设 1 天 “无 AI 日”，自主决策、分析创作。 - 用传统工具脑暴，再用 AI 优化反向验证。 技术脆弱性风险： - AI 系统故障或算法错误，无备用方案致瘫痪，如 ChatGPT 宕机影响开发者。 - 黑客攻击操纵 AI 输出诱导错误决策。 应对策略： - 关键任务配置至少 2 套独立 AI 系统交叉验证。 - 掌握 AI 替代技能的最低手动版本。 伦理与责任模糊风险： - AI 决策失误时人类推诿责任，如特斯拉自动驾驶事故。 - 受 AI 数据偏见输出影响，价值观被侵蚀。 应对策略： - 每月用 IBM AI Fairness 360 检查 AI 输出倾向。 - 重大决策保留人类最终签字确认。 生理机能衰退风险： - 依赖外骨骼等致肌肉萎缩、运动能力下降，如连续使用 3 个月肌力下降 12%。 - 过度依赖 AI 视觉辅助，环境感知灵敏度降低。 应对策略： - 每天 30 分钟无辅助运动。 - 每周 2 次关闭数字设备进行全感官活动。 社会关系异化风险： - 依赖 AI 情感陪伴，现实社交技能退化，如日本 43% 用户沟通焦虑加剧。 - 同理心因 AI 高效解决事务受削弱。 应对策略： - 加入兴趣俱乐部，强制面对面互动。 - 定期组织 AI 伦理讨论。"},
		{"id":"0bbe48a32cf3d7c5","x":-340,"y":-30,"width":250,"height":60,"type":"text","text":"是否完全依赖AI"},
		{"id":"3e60d34ed06d5da5","x":80,"y":160,"width":460,"height":160,"type":"text","text":"遵循人机共生 “20% 原则”： - 时间分配：每日 AI 辅助时长≤80%，20% 纯人工操作。 - 能力储备：对 AI 替代技能保持 20% 基础手动能力。 - 决策权重：重要事务 AI 建议占比≤80%，20% 决策权留给直觉与伦理判断。 保有 “手动模式”，关键能力不废弃；建立 “熔断机制”，异常时切换自主控制。"}
	],
	"edges":[
		{"id":"825cd6b04f54e218","fromNode":"0bbe48a32cf3d7c5","fromSide":"right","toNode":"d866dfdbea90a30d","toSide":"left"},
		{"id":"575b358d959d4506","fromNode":"0bbe48a32cf3d7c5","fromSide":"right","toNode":"3e60d34ed06d5da5","toSide":"left"}
	]
}